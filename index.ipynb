{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactions - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll explore interactions in the Boston Housing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be able to:\n",
    "- Implement interaction terms in Python using the `sklearn` and `statsmodels` packages \n",
    "- Interpret interaction variables in the context of a real-world problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a baseline model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll use a couple of built-in functions, which we imported for you below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Boston data set using `load_boston()`. We won't bother to preprocess the data in this lab. If you still want to build a model in the end, you can do that, but this lab will just focus on finding meaningful insights in interactions and how they can improve $R^2$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = LinearRegression()\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#My code\n",
    "boston_features = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "X = boston_features\n",
    "y = pd.DataFrame(boston.target, columns=['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7190106820189477"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#their code\n",
    "y = pd.DataFrame(boston.target,columns = ['target'])\n",
    "df = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "all_data = pd.concat([y,df], axis = 1)\n",
    "\n",
    "crossvalidation = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "baseline = np.mean(cross_val_score(regression, df, y, scoring='r2', cv=crossvalidation))\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a baseline model which includes all the variables in the Boston housing data set to predict the house prices. Then use 10-fold cross-validation and report the mean $R^2$ value as the baseline $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "## my code here\n",
    "cross_validation = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "baseline = np.mean(cross_val_score(regression,X,y,scoring='r2', cv=cross_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7190106820189477"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See how interactions improve your baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create all possible combinations of interactions, loop over them and add them to the baseline model one by one to see how they affect the $R^2$. We'll look at the 3 interactions which have the biggest effect on our $R^2$, so print out the top 3 combinations.\n",
    "\n",
    "You will create a `for` loop to loop through all the combinations of 2 predictors. You can use `combinations` from itertools to create a list of all the pairwise combinations. To find more info on how this is done, have a look [here](https://docs.python.org/2/library/itertools.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "combinations = list(combinations(boston.feature_names, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mycode\n",
    "interaction_combos = {}\n",
    "data = X\n",
    "for combo in combinations:    \n",
    "    interaction = data[combo[0]] * data[combo[1]]\n",
    "    #interaction = boston_features[combinations[0][0]] * boston_features[combinations[0][1]]\n",
    "    interaction_name = combo[0] + \"_\"+ combo[1]\n",
    "    #interaction_name = combinations[0][0] + \"_\"+ combinations[0][1]\n",
    "    data[interaction_name] = interaction\n",
    "    cross_validation = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    baseline = np.mean(cross_val_score(regression,data,y,scoring='r2', cv=cross_validation))\n",
    "    interaction_combos[interaction_name] = baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['TAX_PTRATIO', 0.8532317331733953],\n",
       " ['TAX_B', 0.8531244563973182],\n",
       " ['TAX_LSTAT', 0.8528562547505093]]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## code to find top 3 interactions by R^2 value here\n",
    "[[k, v] for k, v in sorted(interaction_combos.items(), key=lambda item: item[1], reverse=True)][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 interactions: [('RM', 'LSTAT', 0.786), ('RM', 'TAX', 0.775), ('RM', 'RAD', 0.768), ('RM', 'PTRATIO', 0.763), ('INDUS', 'RM', 0.758)]\n"
     ]
    }
   ],
   "source": [
    "#their code\n",
    "interactions = []\n",
    "data = df.copy()\n",
    "for comb in combinations:\n",
    "    data['interaction'] = data[comb[0]] * data[comb[1]]\n",
    "    score = np.mean(cross_val_score(regression, data, y, scoring='r2', cv=crossvalidation))\n",
    "    if score > baseline: interactions.append((comb[0], comb[1], round(score,3)))\n",
    "            \n",
    "print('Top 3 interactions: %s' %sorted(interactions, key=lambda inter: inter[2], reverse=True)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#their code with my X as a copy\n",
    "interactions = []\n",
    "data = X.copy()\n",
    "for comb in combinations:\n",
    "    data['interaction'] = data[comb[0]] * data[comb[1]]\n",
    "    score = np.mean(cross_val_score(regression, data, y, scoring='r2', cv=cross_validation))\n",
    "    if score > baseline: interactions.append((comb[0], comb[1], round(score,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 interactions: [('CRIM', 'ZN', 0.846), ('CRIM', 'INDUS', 0.846), ('CRIM', 'CHAS', 0.846), ('CRIM', 'NOX', 0.846), ('CRIM', 'RM', 0.846)]\n"
     ]
    }
   ],
   "source": [
    "print('Top 3 interactions: %s' %sorted(interactions, key=lambda inter: inter[2], reverse=True)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the top 3 interactions: \"RM\" as a confounding factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top three interactions seem to involve \"RM\", the number of rooms as a confounding variable for all of them. Let's have a look at interaction plots for all three of them. This exercise will involve:\n",
    "\n",
    "- Splitting the data up in 3 groups: one for houses with a few rooms, one for houses with a \"medium\" amount of rooms, one for a high amount of rooms \n",
    "- Create a function `build_interaction_rm()`. This function takes an argument `varname` (which can be set equal to the column name as a string) and a column `description` (which describes the variable or varname, to be included on the x-axis of the plot). The function outputs a plot that uses \"RM\" as a confounding factor. Each plot should have three regression lines, one for each level of \"RM\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been split into high, medium, and low number of rooms for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = np.asarray(df[['RM']]).reshape(len(df[['RM']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_rm = all_data[rm > np.percentile(rm, 67)]\n",
    "med_rm = all_data[(rm > np.percentile(rm, 33)) & (rm <= np.percentile(rm, 67))]\n",
    "low_rm = all_data[rm <= np.percentile(rm, 33)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `build_interaction_rm()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_interaction_rm(varname, description):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use `build_interaction_rm()` with the three variables that came out with the highest effect on $R^2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a final model including all three interactions at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 10-fold cross-validation to build a model using all the above interactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our $R^2$ has increased considerably! Let's have a look in `statsmodels` to see if all these interactions are significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is your conclusion here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formulate your conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now understand how to include interaction effects in your model! As you can see, interactions can have a strong impact on linear regression models, and they should always be considered when you are constructing your models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
